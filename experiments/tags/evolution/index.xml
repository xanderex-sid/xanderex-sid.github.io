<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Evolution on Lil&#39;Log</title>
    <link>https://lilianweng.github.io/tags/evolution/</link>
    <description>Recent content in Evolution on Lil&#39;Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Aug 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://lilianweng.github.io/tags/evolution/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Neural Architecture Search</title>
      <link>https://lilianweng.github.io/posts/2020-08-06-nas/</link>
      <pubDate>Thu, 06 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2020-08-06-nas/</guid>
      <description>&lt;!-- Neural Architecture Search (NAS) automates network architecture engineering. It aims to learn a network topology that can achieve best performance on a certain task. By dissecting the methods for NAS into three components: search space, search algorithm and child model evolution strategy, this post reviews many interesting ideas for better, faster and more cost-efficient automatic neural architecture search. --&gt;
&lt;p&gt;Although most popular and successful model architectures are designed by human experts, it doesn&amp;rsquo;t mean we have explored the entire network architecture space and settled down with the best option. We would have a better chance to find the optimal solution if we adopt a systematic and automatic way of learning high-performance model architectures.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Evolution Strategies</title>
      <link>https://lilianweng.github.io/posts/2019-09-05-evolution-strategies/</link>
      <pubDate>Thu, 05 Sep 2019 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2019-09-05-evolution-strategies/</guid>
      <description>&lt;!-- Gradient descent is not the only option when learning optimal model parameters. Evolution Strategies (ES)  works out well in the cases where we don&#39;t know the precise analytic form of an objective function or cannot compute the gradients directly. This post dives into several classic ES methods, as well as how ES can be used in deep reinforcement learning. --&gt;
&lt;p&gt;Stochastic gradient descent is a universal choice for optimizing deep learning models. However, it is not the only option. With black-box optimization algorithms, you can evaluate a target function $f(x): \mathbb{R}^n \to \mathbb{R}$, even when you don&amp;rsquo;t know the precise analytic form of $f(x)$ and thus cannot compute gradients or the Hessian matrix. Examples of black-box optimization methods include &lt;a href=&#34;https://en.wikipedia.org/wiki/Simulated_annealing&#34;&gt;Simulated Annealing&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Hill_climbing&#34;&gt;Hill Climbing&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method&#34;&gt;Nelder-Mead method&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
