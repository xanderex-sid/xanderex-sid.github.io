<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Data on Lil&#39;Log</title>
    <link>https://lilianweng.github.io/tags/data/</link>
    <description>Recent content in Data on Lil&#39;Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 05 Feb 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://lilianweng.github.io/tags/data/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Thinking about High-Quality Human Data</title>
      <link>https://lilianweng.github.io/posts/2024-02-05-human-data-quality/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2024-02-05-human-data-quality/</guid>
      <description>&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Special thank you to &lt;a href=&#34;https://scholar.google.com/citations?user=FRBObOwAAAAJ&amp;amp;hl=en&#34;&gt;Ian Kivlichan&lt;/a&gt; for many useful pointers (E.g. the 100+ year old Nature paper &amp;ldquo;Vox populi&amp;rdquo;) and nice feedback. üôè ]&lt;/span&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;High-quality data is the fuel for modern data deep learning model training. Most of the task-specific labeled data comes from human annotation, such as classification task or &lt;a href=&#34;https://lilianweng.github.io/posts/2021-01-02-controllable-text-generation/#rl-fine-tuning-with-human-preferences&#34;&gt;RLHF&lt;/a&gt; labeling (which can be constructed as classification format) for LLM alignment training. Lots of ML techniques in the post can help with data quality, but fundamentally human data collection involves attention to details and careful execution. The community knows the value of high quality data, but somehow we have this subtle impression that ‚ÄúEveryone wants to do the model work, not the data work‚Äù (&lt;a href=&#34;https://dl.acm.org/doi/abs/10.1145/3411764.3445518&#34;&gt;Sambasivan et al. 2021&lt;/a&gt;).&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Learning with not Enough Data Part 3: Data Generation</title>
      <link>https://lilianweng.github.io/posts/2022-04-15-data-gen/</link>
      <pubDate>Fri, 15 Apr 2022 15:10:30 -0700</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2022-04-15-data-gen/</guid>
      <description>&lt;p&gt;Here comes the Part 3 on learning with not enough data (Previous: &lt;a href=&#34;https://lilianweng.github.io/posts/2021-12-05-semi-supervised/&#34;&gt;Part 1&lt;/a&gt; and &lt;a href=&#34;https://lilianweng.github.io/posts/2022-02-20-active-learning/&#34;&gt;Part 2&lt;/a&gt;). Let‚Äôs consider two approaches for generating synthetic data for training.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Augmented data&lt;/strong&gt;. Given a set of existing training samples, we can apply a variety of augmentation, distortion and transformation to derive new data points without losing the key attributes. We have covered a bunch of augmentation methods on text and images in a &lt;a href=&#34;https://lilianweng.github.io/posts/2021-05-31-contrastive/&#34;&gt;previous post&lt;/a&gt; on contrastive learning. For the sake of post completeness, I &lt;em&gt;duplicate&lt;/em&gt; the section on data augmentation here with some edits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;New data&lt;/strong&gt;. Given few or even no data points, we can rely on powerful pretrained models to generate a number of &lt;em&gt;new&lt;/em&gt; data points. This is especially true in recent years given the fast progress in large pretrained &lt;a href=&#34;https://lilianweng.github.io/posts/2019-01-31-lm/&#34;&gt;language models (LM)&lt;/a&gt;. Few shot prompting is shown to be effective for LM to learn within context without extra training.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;data-augmentation&#34;&gt;Data Augmentation&lt;/h1&gt;
&lt;p&gt;The goal of data augmentation is to modify the input format (e.g. text wording, visual appearance) while the semantic meaning stays unchanged.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Learning with not Enough Data Part 2: Active Learning</title>
      <link>https://lilianweng.github.io/posts/2022-02-20-active-learning/</link>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2022-02-20-active-learning/</guid>
      <description>&lt;!-- The performance of supervised learning tasks improves with more high-quality labels available. However, it is expensive to collect a large number of labeled samples. Active learning is one paradigm to deal with not enough labeled data, when there are resources for labeling more data samples but under a limited budget. --&gt;
&lt;p&gt;This is part 2 of what to do when facing a limited amount of labeled data for supervised learning tasks. This time we will get some amount of human labeling work involved, but within a budget limit, and therefore we need to be smart when selecting which samples to label.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Learning with not Enough Data Part 1: Semi-Supervised Learning</title>
      <link>https://lilianweng.github.io/posts/2021-12-05-semi-supervised/</link>
      <pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2021-12-05-semi-supervised/</guid>
      <description>&lt;!-- The performance of supervised learning tasks improves with more high-quality labels available. However, it is expensive to collect a large number of labeled samples. There are several paradigms in machine learning to deal with the scenario when the labels are scarce. Semi-supervised learning is one candidate, utilizing a large amount of unlabeled data conjunction with a small amount of labeled data. --&gt;
&lt;p&gt;When facing a limited amount of labeled data for supervised learning tasks, four approaches are commonly discussed.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
