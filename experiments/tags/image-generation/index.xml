<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Image-Generation on Lil&#39;Log</title>
    <link>https://lilianweng.github.io/tags/image-generation/</link>
    <description>Recent content in Image-Generation on Lil&#39;Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Jul 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://lilianweng.github.io/tags/image-generation/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What are Diffusion Models?</title>
      <link>https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</guid>
      <description>&lt;!-- Diffusion models are a new type of generative models that are flexible enough to learn any arbitrarily complex data distribution while tractable to analytically evaluate the distribution. It has been shown recently that diffusion models can generate high-quality images and the performance is competitive to SOTA GAN. --&gt;
&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Updated on 2021-09-19: Highly recommend this blog post on &lt;a href=&#34;https://yang-song.github.io/blog/2021/score/&#34;&gt;score-based generative modeling&lt;/a&gt; by Yang Song (author of several key papers in the references)].&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2022-08-27: Added &lt;a href=&#34;#classifier-free-guidance&#34;&gt;classifier-free guidance&lt;/a&gt;, &lt;a href=&#34;#glide&#34;&gt;GLIDE&lt;/a&gt;, &lt;a href=&#34;#unclip&#34;&gt;unCLIP&lt;/a&gt; and &lt;a href=&#34;#imagen&#34;&gt;Imagen&lt;/a&gt;.&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2022-08-31: Added &lt;a href=&#34;#ldm&#34;&gt;latent diffusion model&lt;/a&gt;.&lt;/span&gt;&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2024-04-13: Added &lt;a href=&#34;#prog-distll&#34;&gt;progressive distillation&lt;/a&gt;, &lt;a href=&#34;#consistency&#34;&gt;consistency models&lt;/a&gt;, and the &lt;a href=&#34;#model-architecture&#34;&gt;Model Architecture section&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Flow-based Deep Generative Models</title>
      <link>https://lilianweng.github.io/posts/2018-10-13-flow-models/</link>
      <pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2018-10-13-flow-models/</guid>
      <description>&lt;!-- In this post, we are looking into the third type of generative models: flow-based generative models. Different from GAN and VAE, they explicitly learn the probability density function of the input data. --&gt;
&lt;p&gt;So far, I&amp;rsquo;ve written about two types of generative models, &lt;a href=&#34;https://lilianweng.github.io/posts/2017-08-20-gan/&#34;&gt;GAN&lt;/a&gt; and &lt;a href=&#34;https://lilianweng.github.io/posts/2018-08-12-vae/&#34;&gt;VAE&lt;/a&gt;. Neither of them explicitly learns the probability density function of real data, $p(\mathbf{x})$ (where $\mathbf{x} \in \mathcal{D}$) &amp;mdash; because it is really hard! Taking the generative model with latent variables as an example, $p(\mathbf{x}) = \int p(\mathbf{x}\vert\mathbf{z})p(\mathbf{z})d\mathbf{z}$ can hardly be calculated as it is intractable to go through all possible values of the latent code $\mathbf{z}$.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>From Autoencoder to Beta-VAE</title>
      <link>https://lilianweng.github.io/posts/2018-08-12-vae/</link>
      <pubDate>Sun, 12 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2018-08-12-vae/</guid>
      <description>&lt;!-- Autocoders are a family of neural network models aiming to learn compressed latent variables of high-dimensional data. Starting from the basic autocoder model, this post reviews several variations, including denoising, sparse, and contractive autoencoders, and then Variational Autoencoder (VAE) and its modification beta-VAE. --&gt;
&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Updated on 2019-07-18: add a section on &lt;a href=&#34;#vq-vae-and-vq-vae-2&#34;&gt;VQ-VAE &amp;amp; VQ-VAE-2&lt;/a&gt;.]&lt;/span&gt;
&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2019-07-26: add a section on &lt;a href=&#34;#td-vae&#34;&gt;TD-VAE&lt;/a&gt;.]&lt;/span&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Autocoder is invented to reconstruct high-dimensional data using a neural network model with a narrow bottleneck layer in the middle (oops, this is probably not true for &lt;a href=&#34;#vae-variational-autoencoder&#34;&gt;Variational Autoencoder&lt;/a&gt;, and we will investigate it in details in later sections). A nice byproduct is dimension reduction: the bottleneck layer captures a compressed latent encoding. Such a low-dimensional representation can be used as en embedding vector in various applications (i.e. search), help data compression, or reveal the underlying data generative factors.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>From GAN to WGAN</title>
      <link>https://lilianweng.github.io/posts/2017-08-20-gan/</link>
      <pubDate>Sun, 20 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://lilianweng.github.io/posts/2017-08-20-gan/</guid>
      <description>&lt;!-- This post explains the maths behind a generative adversarial network (GAN) model and why it is hard to be trained. Wasserstein GAN is intended to improve GANs&#39; training by adopting a smooth metric for measuring the distance between two probability distributions. --&gt;
&lt;p&gt;&lt;span class=&#34;update&#34;&gt;[Updated on 2018-09-30: thanks to Yoonju, we have this post translated in &lt;a href=&#34;https://github.com/yjucho1/articles/blob/master/fromGANtoWGAN/readme.md&#34;&gt;Korean&lt;/a&gt;!]&lt;/span&gt;
&lt;br/&gt;
&lt;span class=&#34;update&#34;&gt;[Updated on 2019-04-18: this post is also available on &lt;a href=&#34;https://arxiv.org/abs/1904.08994&#34;&gt;arXiv&lt;/a&gt;.]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1406.2661.pdf&#34;&gt;Generative adversarial network&lt;/a&gt; (GAN) has shown great results in many generative tasks to replicate the real-world rich content such as images, human language, and music. It is inspired by game theory: two models, a generator and a critic, are competing with each other while making each other stronger at the same time. However, it is rather challenging to train a GAN model, as people are facing issues like training instability or failure to converge.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
